{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CONVOLUTION.\n",
    "\n",
    "it is the mathematical tool for each pixel and change its value accordingly.\n",
    "KerneL is the matrix with odd dimensions.it change the value of the centre pixel which according to kernel.\n",
    "kernel is also called image filter.\n",
    "identity kernel is simply a 3*3 matrix with 1 at centre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   BLURRING.\n",
    "\n",
    "it is refer to averaging the pixel values within a neighborhood.\n",
    "it is also called LOW PASS FILTER. \n",
    "It allow the low frequencies and block the high frequencies.\n",
    "FREQUENCY  here is the rate of change of pixel values.\n",
    "*** sharp edges would have high frequencies because the pixel values changes rapidly there.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     L=1/9[1 1  1\n",
    "   #         1  1 1\n",
    "   #         1  1  1]\n",
    "\n",
    "this 3X3 low pass filter\n",
    "we are dividing  the matrix by 9 because we want\n",
    "the value to sum up to 1\n",
    "it is called*** NORMALIZATION***.\n",
    "*** IT IS IMPORTANT BECAUSE WE DONT WNAT TO ARTIFICALLY INCREASE THE \n",
    "INTENSITY VALUE AT THE PIXEL' LOCATION.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# APPLYING  A BLURRING KERNEL.\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "img=cv2.imread(\"input.jpg\")\n",
    "row,col=img.shape[:2]\n",
    "\n",
    "kernel_identity= np.array(([0,0,0], [0,1,0], [0,0,0]),np.int8)\n",
    "\n",
    "kernel_3x3=np.ones((3,3),np.float32)/9.0\n",
    "\n",
    "kernel_5x5=np.ones((5,5),np.float32)/25.0\n",
    "\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "output=cv2.filter2D(img,-1,kernel_identity)\n",
    "cv2.imshow('identity filter',output)\n",
    "\n",
    "output=cv2.filter2D(img,-1,kernel_3x3)\n",
    "cv2.imshow(\"3x3 filter\",output)\n",
    "\n",
    "output=cv2.filter2D(img,-1,kernel_5x5)\n",
    "cv2.imshow(\"5x5 filter\",output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#we can use cv2.blur(frame,(3,3))\n",
    "#directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EDGE DETECTION\n",
    "it involves detecting sharp edges in image and produce binary as the output.\n",
    "white lines to show edge in black background.\n",
    "it act as *** high pass filter ***\n",
    "\n",
    "we use *** SOBEL FILTERS *** for it.\n",
    "\n",
    "# Sx=[ -1, 0,1\n",
    " #        -2,0,2\n",
    " #         -1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img=cv2.imread(\"input.jpg\",cv2.IMREAD_GRAYSCALE)\\nrows,cols =img.shape\\nsobel_horizontal=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\\nsobel_vertical=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\\n\\ncv2.imshow(\\'orignial\\',img)\\n#cv2.imshow(\\'sobel_horizontal\\',sobel_horizontal)\\n#cv2.imshow(\\'sobel_vertical\\',sobel_vertical)\\n\\nlap=cv2.Laplacian(img,cv2.CV_64F)\\ncanny=cv2.Canny(img,50,240)\\ncv2.imshow(\"laplacian\",lap)\\ncv2.imshow(\"cannyedge\",canny)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the sobel filter\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img=cv2.imread(\"input.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "rows,cols =img.shape\n",
    "sobel_horizontal=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "sobel_vertical=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "cv2.imshow('orignial',img)\n",
    "#cv2.imshow('sobel_horizontal',sobel_horizontal)\n",
    "#cv2.imshow('sobel_vertical',sobel_vertical)\n",
    "\n",
    "lap=cv2.Laplacian(img,cv2.CV_64F)\n",
    "canny=cv2.Canny(img,50,240)\n",
    "cv2.imshow(\"laplacian\",lap)\n",
    "cv2.imshow(\"cannyedge\",canny)\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL TIME EDGE DETECTION THROUGH WEBCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real time edge detection \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    img=cv2.Canny(frame,50,240)\n",
    "    cv2.imshow(\"video\",img)\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xff==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOTION BLUR\n",
    "\n",
    "it looks as it is taken form moving object\n",
    "In this also we are constructing a motion blur kernel.\n",
    "*** A MOTION BLUR KERNEL AVERAGES THE PIXEL VALUES IN A PARTICULAR DIRECTION. IT ACT AS A DIRECTIONAL LOW PASS FILTER. ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HORIZONTAL DIRECTIONAL BLUR\n",
    "\n",
    "# KERNEL IS\n",
    "# [ 0       0         0\n",
    "#   1       1          1\n",
    "#   0       0          0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread(\"input.jpg\")\n",
    "kernel=np.array(([0,0,0],[1,1,1],[0,0,0]),np.int8)\n",
    "motion=cv2.filter2D(img,-1,kernel)\n",
    "cv2.imshow(\"motion blur\",motion)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening\n",
    "\n",
    "it will sharpen the edges in the images.\n",
    "some kernel are\n",
    "# [ -1 -1 -1\n",
    "#  -1  9  -1\n",
    "#   -1  -1  -1]\n",
    "\n",
    "*** IN BELOW CODE WE DONOT DIVIDE ONE AND TWO KERNEL BY NORMALIZING FACTOR  BECAUSE THE VALUE INSIDE THE KERNEL ALREADY SUM UP TO 1  Make sure that you\n",
    "normalize the kernel before applying it, or else the image will look too bright because\n",
    "you are artificially increasing the pixel values in the image.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying filters\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread('input.jpg')\n",
    "cv2.imshow('original',img)\n",
    "# generating the kernels\n",
    "\n",
    "\n",
    "kernel_one=np.array(([-1,-1,-1],[-1,9,-1],[-1,-1,-1]))\n",
    "\n",
    "kernel_two=np.array(([1,1,1],[1,-7,1],[1,1,1]))\n",
    "\n",
    "kernel_three= np.array([[-1,-1,-1,-1,-1],\n",
    "                         [-1,2,2,2,-1],\n",
    "                         [-1,2,8,2,-1],\n",
    "                         [-1,2,2,2,-1],\n",
    "                         [-1,-1,-1,-1,-1]]) / 8.0\n",
    "\n",
    "#applying kernels\n",
    "\n",
    "output_1=cv2.filter2D(img,-1,kernel_one)\n",
    "output_2=cv2.filter2D(img,-1,kernel_two)\n",
    "output_3=cv2.filter2D(img,-1,kernel_three)\n",
    "\n",
    "cv2.imshow('sharpening',output_1)\n",
    "\n",
    "cv2.imshow(' excessive sharpening',output_2)\n",
    "cv2.imshow('edge enhancement sharpening',output_3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBOSSING\n",
    "\n",
    "IT TAKE EACH PIXEL AND REPLACE IT WITH A SHADOW OR A HIGHLIGHT. The\n",
    "embossing effect is achieved by offsetting all the pixel values in the image by 128.\n",
    "This operation adds the highlight/shadow effect to the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img_emboss_input = cv2.imread('input.jpg')\n",
    "# generating the kernels\n",
    "kernel_emboss_1 = np.array([[0,-1,-1],\n",
    " [1,0,-1],\n",
    " [1,1,0]])\n",
    "kernel_emboss_2 = np.array([[-1,-1,0],\n",
    " [-1,0,1],\n",
    " [0,1,1]])\n",
    "kernel_emboss_3 = np.array([[1,0,0],\n",
    " [0,0,0],\n",
    " [0,0,-1]])\n",
    "# converting the image to grayscale\n",
    "gray_img = cv2.cvtColor(img_emboss_input,cv2.COLOR_BGR2GRAY)\n",
    "# applying the kernels to the grayscale image and adding the offset\n",
    "output_1 = cv2.filter2D(gray_img, -1, kernel_emboss_1) + 128\n",
    "output_2 = cv2.filter2D(gray_img, -1, kernel_emboss_2) + 128\n",
    "output_3 = cv2.filter2D(gray_img, -1, kernel_emboss_3) + 128\n",
    "cv2.imshow('Input', img_emboss_input)\n",
    "cv2.imshow('Embossing - South West', output_1)\n",
    "cv2.imshow('Embossing - South East', output_2)\n",
    "cv2.imshow('Embossing - North West', output_3)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EROSION AND DILATION\n",
    "\n",
    "it used for morphological image processing .it basically deal with modifying geometric structure in the image.\n",
    "*** EROSION:-*** strips out the outermost layer of pixels in structure\n",
    "*** DILATION:-*** adds an extra layer of pixels on a structure.\n",
    "\n",
    "it has third argument is iteration ie how many times you want apply the embossing filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img=cv2.imread('input.jpg')\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "\n",
    "img_erosion=cv2.erode(img,kernel,iterations=1)\n",
    "img_dilation=cv2.dilate(img,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow('input',img)\n",
    "cv2.imshow('EROSION',img_erosion)\n",
    "cv2.imshow('dilation',img_dilation)\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIGNETTE FILTER\n",
    "\n",
    "It basically focus on brightness on a particular part of image and other part look faded.\n",
    "# to do so we\n",
    "\n",
    "WE FILTER OUT EACH CHANNEL USING GAUSSIAN KERNEL.\n",
    "THE second parameter of *** getGaussionKernel*** \n",
    "it is standard deviation of Gaussian and control the radius of bright central region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread('input.jpg')\n",
    "\n",
    "rows,cols=img.shape[:2]\n",
    "\n",
    "#generating vignette mask using gaussion kernels\n",
    "\n",
    "kernel_x=cv2.getGaussianKernel(cols,200)\n",
    "kernel_y=cv2.getGaussianKernel(rows,200)\n",
    "\n",
    "kernel=kernel_y*kernel_x.T\n",
    "\n",
    "mask=255*kernel/np.linalg.norm(kernel)\n",
    "\n",
    "output=np.copy(img)\n",
    "\n",
    "# applying the mask to each channel\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    output[:,:,i]=output[:,:,i]*mask\n",
    "    \n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('vignette',output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTRAST\n",
    "\n",
    "it is for low light and dim image.\n",
    "due to low lighting,the pixel values tend to concentrate near 0 \n",
    "\n",
    "# HISTOGRAM EQUALIZATION\n",
    "\n",
    "*** IT IS ONLY APPLICABLE FOR GRAYSCALE IMAGE***\n",
    "The concept of histogram is only applicable to the intensity values in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('input.jpg')\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "# equalize the histogram of the Y channel\n",
    "img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "# convert the YUV image back to RGB format\n",
    "img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "cv2.imshow('Color input image', img)\n",
    "cv2.imshow('Histogram equalized', img_output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
