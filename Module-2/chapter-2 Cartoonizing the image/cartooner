{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing WEBCAM\n",
    "\n",
    "ret,frame=cap.read()\n",
    "\n",
    "In this *** ret is boolean value returned by the read function.IT TELL WHETHER FRAME CAPTURED IS SUCCESSFUL OR NOT.***\n",
    "\n",
    "*** cap.release():- IT IS IMPORTANT BECAUSE IT GRACEFULLY CLOSES THE WEBCAM ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#check if webcam is on correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"cannot open webcam\")\n",
    "    \n",
    "while True:\n",
    "    ret,frame =cap.read()\n",
    "    \n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    cv2.imshow('input',frame)\n",
    "    c=cv2.waitKey(1)\n",
    "    if c==27:\n",
    "        cv2.imwrite(\"frame.jpg\",frame)\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEYBOARD INPUTS\n",
    "\n",
    "We use argparse libaray for it.\n",
    "we use waitKey():- to listen keyboards.\n",
    "***it return the ASCII value of keystrokes pressed.***\n",
    "\n",
    "***ord() is used to convert to character to ASCII value***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__name___' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-201213687deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0m__name___\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margument_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__name___' is not defined"
     ]
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "\n",
    "def argument_parse():\n",
    "    \n",
    "    parser=argparse.ArgumentParser(description=\"Grayscale - 'g', YUV - 'y', HSV - 'h'\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name___=='__main__':\n",
    "    \n",
    "    args=argument_parser().parse_args()\n",
    "    \n",
    "    cap=cv2.VideoCapture(0)\n",
    "    \n",
    "    #check if the webcam is opened correctly\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"cannot open webcam\")\n",
    "        \n",
    "    cur_char=-1\n",
    "    pre_char=-1\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #read the current frame\n",
    "        ret,frame=cap.read()\n",
    "        \n",
    "        #resize the image\n",
    "        frame=cv2.resize(frame,None,fx=1.5,fy=1.5,interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        c=cv2.waitKey(1)\n",
    "        \n",
    "        if c==27:\n",
    "            break;\n",
    "            \n",
    "        if c>-1 and c!= pre_char:\n",
    "            cur_char=c\n",
    "        pre_char=c\n",
    "        \n",
    "        if cur_char==ord('g'):\n",
    "            output=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        elif cur_char==ord('y'):\n",
    "            output=cv2.cvtColor(frame,cv2.COLOR_BGR2YUV)\n",
    "            \n",
    "        elif cur_char==ord('h'):\n",
    "            output=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "        else:\n",
    "            output=frame\n",
    "            \n",
    "        cv2.imshow('webcam',output)\n",
    "        \n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOUSE INPUTS\n",
    "\n",
    "we will detect in which quadrant the click was made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0002dedeb2c4>\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mpointbottomright\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointtopleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointbottomright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type tuple)"
     ]
    }
   ],
   "source": [
    "#code\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect(event,x,y,flags,param):\n",
    "    \n",
    "    \n",
    "    if event == cv2.EVENT_RBUTTONUP:\n",
    "        if x>width/2:\n",
    "            if y>height/2:\n",
    "                pointtopleft=(int(width/2),int(height/2))\n",
    "                pointbottomright=(width-1,(height-1))\n",
    "                \n",
    "            else:\n",
    "                pointtopleft=(int(width/2),0)\n",
    "                pointbottomright=(width-1,int(height-1))\n",
    "        else:\n",
    "            if y>height/2:\n",
    "                \n",
    "                pointbottomright=(int(width-1),(height-1))\n",
    "                              \n",
    "            else:\n",
    "                pointtopleft=(0,0)\n",
    "                pointbottomright=(width-1,(height-1))\n",
    "                              \n",
    "        cv2.rectangle(img,(0,0),(width-1,height/2),(255,255,255),-1)\n",
    "        cv2.rectangle(img,pointtopleft,pointbottomright,(100,0,0),-1)\n",
    "                              \n",
    "width,height=640,480\n",
    "                              \n",
    "img=255*np.ones((height,width,3),dtype=np.int8)\n",
    "cv2.namedWindow('input window')\n",
    "cv2.setMouseCallback('input window',detect)\n",
    "\n",
    "while True :\n",
    "     cv2.imshow('input window',img)\n",
    "     c=cv2.waitKey(10)\n",
    "     if c==27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***  if above code donot run, then simply remove this line:-if __name___=='__main__': and correct indention.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartoonize an IMAGE\n",
    "\n",
    "we first convert the image to grayscale.\n",
    "#2\n",
    "then we use medianblur to remove salt and peper noise.\n",
    "#3\n",
    "then we detect the edges in frame and make them black and white\n",
    "#4\n",
    "to highlight the edges. erode and dilation is used.*** they treat white pixel as foreground and black as background***\n",
    "\n",
    "#5\n",
    "bilateralfilter is used to smoothen the image.\n",
    "#6\n",
    "***The good thing about bilateral filtering is that it preserves the edges, whereas the\n",
    "Gaussian filter smoothens everything out equally***\n",
    "\n",
    "#7\n",
    "The Gaussian filter just looks at the immediate neighborhood and averages the pixel\n",
    "values using a Gaussian kernel. The bilateral filter takes this concept to the next level\n",
    "by averaging only those pixels that are similar to each other in intensity. It also takes\n",
    "a color neighborhood metric to see if it can replace the current pixel that is similar in\n",
    "intensity as well\n",
    "#8\n",
    "***img_small = cv2.bilateralFilter(img_small, size, sigma_color,\n",
    "sigma_space)***\n",
    "#9\n",
    "The last two arguments here specify the color and space neighborhood. This is the\n",
    "reason the edges look crisp in the output of the bilateral filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def cartoon(img,ds_factor=4,sketch=False):\n",
    "    \n",
    "    # convert image to grayscale\n",
    "    img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #APPLY MEDIAN FILTER TO GRAYSCALE\n",
    "    img_gray=cv2.medianBlur(img_gray,7)# (frame,kernel-size)\n",
    "    \n",
    "    #detect edges in the image and threshold it\n",
    "    edges=cv2.Laplacian(img_gray,cv2.CV_8U,ksize=5)\n",
    "    ret,mask=cv2.threshold(edges,100,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # MASK IS THE SKETCH OF IMAGE\n",
    "    \n",
    "    if sketch:\n",
    "        return cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    #RESIZE THE IMAGE TO SAMLLER SIZE FOR FASTER COMPUTATION\n",
    "    \n",
    "    img_small=cv2.resize(img,None,fx=1/ds_factor,fy=1/ds_factor,interpolation=cv2.INTER_AREA)\n",
    "    num_rep=10\n",
    "    sigmacolor=5\n",
    "    sigmaspace=7\n",
    "    size=5\n",
    "    \n",
    "    #apply bilateral filter the image multiple times\n",
    "    \n",
    "    for i in range(num_rep):\n",
    "        \n",
    "        img_small=cv2.bilateralFilter(img_small,size,sigmacolor,sigmaspace)\n",
    "    \n",
    "    img_output = cv2.resize(img_small, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    dst=np.zeros(img_gray.shape)\n",
    "    # add the thick boundary\n",
    "    \n",
    "    dst=cv2.bitwise_and(img_output,img_output,mask=mask)\n",
    "    return dst\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "    \n",
    "cur_char=-1\n",
    "pre_char=-1\n",
    "    \n",
    "while True:\n",
    "        \n",
    "    ret,frame=cap.read()\n",
    "        \n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "    c=cv2.waitKey(1)\n",
    "    if c==27:\n",
    "        break\n",
    "            \n",
    "    if c>-1 and c!=pre_char:\n",
    "        cur_char=c\n",
    "    pre_char=c\n",
    "        \n",
    "    if cur_char==ord('s'):\n",
    "        cv2.imshow(\"cartoonize\",cartoon(frame,sketch=True))\n",
    "    elif cur_char==ord('c'):\n",
    "        cv2.imshow(\"cartoonize\",cartoon(frame,sketch=False))\n",
    "    else:\n",
    "        cv2.imshow(\"cartoonize\",cartoon(frame))\n",
    "                       \n",
    "    \n",
    "                       \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "                \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
