{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-746ec7fd4769>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-746ec7fd4769>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    from import WindowManager, CaptureManager\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import filters\n",
    "from manager import WindowManager, CaptureManager\n",
    "import rects\n",
    "from tracker import facetracker\n",
    "\n",
    "class click(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._windowmanager=WindowManager('click',self.onkeypress)\n",
    "        \n",
    "        self._capturemanager=CaptureManager(cv2.VideoCapture(0),self._windowmanager,True)\n",
    "        \n",
    "        self._facetracker=facetracker()\n",
    "        self.shoulddrawdebugrects=False\n",
    "        self._curvefilter=filters.bgrportacurvefilter()\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"run the main loop\"\"\"\n",
    "        \n",
    "        self._windowmanager.createwindow()\n",
    "        \n",
    "        while self._windowmanager.iswindowcreated:\n",
    "            \n",
    "            self._capturemanager.enterFrame()\n",
    "            frame=self._capturemanager.frame\n",
    "            \n",
    "            #todo : to track faces and swap in one camera feed\n",
    "            \n",
    "            self._facetracker.update(frame)\n",
    "            faces=self._facetracker.faces\n",
    "            rects.swaprects(frame,frame,\n",
    "                           [face.facerect for face in faces])\n",
    "            \n",
    "            #todo to add filters\n",
    "            \n",
    "            filters.strokeedge(frame,frame)\n",
    "            self._curvefilter.apply(frame,frame)\n",
    "            \n",
    "            \n",
    "            if self._shoulddrawdebugrects:\n",
    "                self._facetracker.drawdebugrects(frame)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            self._capturemanager.exitframe()\n",
    "            self._windowmanager.processevents()\n",
    "            \n",
    "    def onkeypress(self,keycode):\n",
    "        \n",
    "        \"\"\"handle a keypress\n",
    "            \n",
    "            space-> take a screenshot\n",
    "            \n",
    "            tab-> start/stop recording a screenshot\n",
    "            \n",
    "            x-> start/stop drawing debug rectangles around faces\n",
    "            \n",
    "            escape-> quit\n",
    "            \"\"\"\n",
    "        if keycode == 32:# space\n",
    "            self._capturemanager.writeimage('screenshot.png')\n",
    "            \n",
    "        elif keycode == 9: #tab\n",
    "            if not self._capturemanager.iswritingvideo:\n",
    "                self._capturemanager.startwritingvideo('screenshot.avi',360)\n",
    "                \n",
    "            else:\n",
    "                self._capturemanager.stopwritingvideo()\n",
    "        elif keycode==120: #x\n",
    "            self._shoulddrawdebugrects= not self.shoulddrawdebugrects\n",
    "        \n",
    "        elif keycode==27: #esc\n",
    "            self._windowmanager.destroywindow()\n",
    "            \n",
    "            \n",
    "            \n",
    "class clickdouble(click):\n",
    "    \n",
    "    def __init__(self):\n",
    "        click.__init__(self)\n",
    "        self._hiddencapturemanager=capturemanager(cv2.VideoCapture(1))\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"run the main loop\"\"\"\n",
    "        \n",
    "        self._windowmanager.createwindow()\n",
    "        while self._windowmanager.enterframe():\n",
    "            \n",
    "            self._capturemanager.enterframe()\n",
    "            self._hiddencapturemanager.enterframe()\n",
    "            \n",
    "            frame=self._capturemanager.frame\n",
    "            hiddenframe=self._hiddencapturemanager.frame\n",
    "            \n",
    "            \n",
    "            self._facetracker.update(hiddenframe)\n",
    "            \n",
    "            hiddenfaces=self._facetracker.faces\n",
    "            \n",
    "            self._facetracker.update(frame)\n",
    "            faces=self._facetracker.faces\n",
    "            \n",
    "            i=0\n",
    "            while i<len(faces) and i < len(hiddenfaces):\n",
    "                \n",
    "                rects.copyrect(hiddenframe,frame,hiddenfaces[i].facerect,\n",
    "                              faces[i].facerect)\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "            filters.strokeedges(frame,frame)\n",
    "            \n",
    "            self._curvefilter.apply(frame,frame)\n",
    "            \n",
    "            if self._shoulddrawdebugrects:\n",
    "                self._facetracker.drawdebugrects(frame)\n",
    "                \n",
    "            self._capturemanager.exitframe()\n",
    "            self.hiddencapturemanager.exitframe()\n",
    "            self._windowmanager.processEvents()\n",
    "            \n",
    "            \n",
    "if __name__==\"__main__\":\n",
    "    click().run()#uncomment for single camera\n",
    "    #clickdouble().run()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manager.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class CaptureManager(object):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self,capture,previewWindowManager=None,\n",
    "                 shouldMirrorPreview=False):\n",
    "       \n",
    "        self.previewWindowManager=previewWindowManager\n",
    "        self.shouldMirrorPreview=shouldMirrorPreview\n",
    "        \n",
    "        self._capture=capture\n",
    "        self._channel=0;\n",
    "        self._enteredframe=False\n",
    "        self._frame=None\n",
    "        \n",
    "        self._imagefilename=None\n",
    "        self._videofilename=None\n",
    "        self._videoencoding=0\n",
    "        self._videowriter=None\n",
    "        \n",
    "        self._starttime=None\n",
    "        self._frameselapsed=long(0)\n",
    "        self._fpsestimate=None\n",
    "        \n",
    "    @property   \n",
    "    def channel(self):\n",
    "        return self._channel\n",
    "    \n",
    "    \n",
    "    \n",
    "    @channel.setter\n",
    "    def channel(self,value):\n",
    "        if self._channel != value:\n",
    "            self._channel=value\n",
    "            self._frame=None\n",
    "            \n",
    "    @property\n",
    "    def frame(self):\n",
    "        if self._enteredframe and self._frame is None:\n",
    "            _,self._frame=self._capture.retrieve(channel=self.channel)\n",
    "        \n",
    "        return self._frame\n",
    "    \n",
    "    @property\n",
    "    def isWritingImage(self):\n",
    "        return self._imagefilename is not None\n",
    "    \n",
    "    @property\n",
    "    def isWritingVideo(self):\n",
    "        return self._videofilename is not None\n",
    "    \n",
    "    \n",
    "    def enterframe(self):\n",
    "        #capture the next frame if any\n",
    "        \n",
    "        #but check if there if any other frame\n",
    "        \n",
    "        \n",
    "        if self._capture is not None:\n",
    "            self._enteredframe=self._capture.grab()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def exitframe(self):\n",
    "        \n",
    "        #to check whether any grabbed frame is retrievable.\n",
    "        if self.frame is not None:\n",
    "            self._enteredframe=False\n",
    "            return\n",
    "        \n",
    "        #update the fps estimate and related variables\n",
    "        \n",
    "        if self._frameselasped == 0:\n",
    "            self._starttime=time.time()\n",
    "        \n",
    "        else:\n",
    "            timeelasped=time.time()-self._starttime\n",
    "            self._fpsestimate=self._frameselapsed/timeelasped\n",
    "            \n",
    "        self._frameselapsed+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #draw a window ,if any.\n",
    "        \n",
    "        \n",
    "        if self.previewWindowManager is not None:\n",
    "            if self.shouldMirrorPreview:\n",
    "                \n",
    "                mirroredframe=np.fliplr(self._frame).copy()\n",
    "                self.previewWindowManager.show(self.frame)\n",
    "                \n",
    "                \n",
    "        #write image file if any is present\n",
    "        \n",
    "        if self.iswritingimage:\n",
    "            cv2.imwriter(self.imagefilename,self.frame)\n",
    "            self._imagefilename=None\n",
    "            \n",
    "        #write  to the video file\n",
    "        \n",
    "        self.writevideoframe()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #release the frame\n",
    "        \n",
    "        self._frame=None\n",
    "        self._enteredframe=False\n",
    "        \n",
    "                \n",
    "    def writeimage(self,filename):\n",
    "        \"\"\"writing next exited frame to an image file\"\"\"\n",
    "        \n",
    "        self.imagefilename=filename\n",
    "        \n",
    "    \n",
    "    def startwritingvideo(self,filename,encoding=360):\n",
    "        \n",
    "        \"\"\"start writing exited filename to video filename\"\"\"\n",
    "        \n",
    "        self._videofilename=filename\n",
    "        self._videoencoding=encoding\n",
    "        \n",
    "        \n",
    "    def stopwritingvideo(self):\n",
    "        \"\"\"stop writing exited frame to a video file.\"\"\"\n",
    "        \n",
    "        self._videofilename=None\n",
    "        self._videoencoding=None\n",
    "        self._videowriter=None\n",
    "        \n",
    "        \n",
    "    def writevideoframe(self):\n",
    "          \n",
    "        if not self.iswritingvideo:\n",
    "            return\n",
    "        \n",
    "        if self._videowriter is None:\n",
    "            \n",
    "            fps=self._capture.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "            \n",
    "            if fps==0.0:\n",
    "                #the capture's fps is unknown so use an estimate.\n",
    "                if self._frameselapsed < 20:\n",
    "                    \"\"\"wait until more frame elapsed so that the estimate is more stable\"\"\"\n",
    "                    return\n",
    "                else:\n",
    "                    fps=self._fpsestimate\n",
    "            \n",
    "            size=(int(self._capture.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH)),\n",
    "                 int(self._capture.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT)))\n",
    "            \n",
    "            self._videowriter=cv2.VideoWriter(self._videofilename,self._videoencoding ,fps,size)\n",
    "        \n",
    "                  \n",
    "                  \n",
    "        self._videowriter.write(self._frame)      \n",
    "    \n",
    "                  \n",
    "                  \n",
    "                  \n",
    "\n",
    "                \n",
    "                \n",
    "                  \n",
    "class WindowManager(object):\n",
    "    \n",
    "                  \n",
    "    \n",
    "                  \n",
    "    def __init__(self,windowname,keypresscallback=None):\n",
    "        self.keypresscallback=keypresscallback\n",
    "        self._windowname=windowname\n",
    "        self._iswindowcreated=False\n",
    "                  \n",
    "            \n",
    "                  \n",
    "            \n",
    "    def iswindowcreated(self):\n",
    "                  \n",
    "        return self._iswindowcreated\n",
    "                  \n",
    "    def createwindow(self):\n",
    "        cv2.namedWindow(self._windowname)\n",
    "        self._iswindowcreated=True\n",
    "                  \n",
    "            \n",
    "    def show(self,frame):\n",
    "        cv2.imshow(self._windowname,frame)\n",
    "                  \n",
    "    def destroywindow(self):\n",
    "        cv2.destroyWindow(self._windowname)\n",
    "        self._iswindowcreated=False\n",
    "                  \n",
    "    def processevents(self):\n",
    "        keycode=cv2.waitKey(1)\n",
    "                 \n",
    "        if self.keypresscallback is not None and keycode != -1:\n",
    "                  \n",
    "                  keycode&= 0xFF\n",
    "                  self.keypresscallback(keycode)\n",
    "\n",
    "                   \n",
    "                  \n",
    "            \n",
    "                  \n",
    "                  \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import util as ut\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class vfuncfilter(object):\n",
    "    \n",
    "    \"\"\"a filter  that applies a function to V(or all of bgr)\"\"\"\n",
    "    \n",
    "    def __init__(self,vfunc=None,dtype=np.uint8):\n",
    "        length=np.iinfo(dtype).max+1\n",
    "        self._vlookuparray=ut.createlookuparray(vfunc,length)\n",
    "        \n",
    "    \n",
    "    def apply(self,src,dst):\n",
    "        \"\"\"apply the filter with a bgr or gray source/destination\"\"\"\n",
    "        \n",
    "        srcflatview=ut.flatview(src)\n",
    "        dstflatview=ut.flatview(dst)\n",
    "        ut.applylookuparray(self._vlookuparray,srcflatview,dstflatview)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "class vcurvefilter(vfuncfilter):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"a filter which apply a curve to v(all bgr)\"\"\"\n",
    "    \n",
    "    def __init__(self,vpoints,dtype=np.uint8):\n",
    "        \n",
    "        vfuncfilter.__init__(self,ut.createcurvefunc(vpoints),dtype)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class bgrfuncfilter(object):\n",
    "    \"\"\"a filter that applies different function to each of bgr.\"\"\"\n",
    "    \n",
    "    def __init__(self,vfunc=None,bfunc=None,gfunc=None,rfunc=None,dtype=np.uint8):\n",
    "        \n",
    "        length=np.iinfo(dtype).max+1\n",
    "        \n",
    "        self._blookuparray=ut.createlookuparray(\n",
    "            ut.createcompositefunc(bfunc,vfunc),length)\n",
    "        self._glookuparray=ut.createlookuparray(\n",
    "            ut.createcompositefunc(gfunc,vfunc),length)\n",
    "        self._rlookuparray=ut.createlookuparray(\n",
    "            ut.createcompositefunc(rfunc,vfunc),length)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def apply(self,src,dst):\n",
    "        \"\"\"apply the filters with a bgr source/destination\"\"\"\n",
    "        \n",
    "        b,g,r=cv2.split(src)\n",
    "        \n",
    "        ut.applylookuparray(self._blookuparray,b,b)\n",
    "        \n",
    "        ut.applylookuparray(self._blookuparray,b,b)\n",
    "        \n",
    "        ut.applylookuparray(self._blookuparray,b,b)\n",
    "        \n",
    "        cv2.merge([b,g,r],dst)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class bgrcurvefilter(bgrfuncfilter):\n",
    "    \"\"\"a filter that applies different curves to each of bgr\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vpoints=None,\n",
    "                 bpoints=None,\n",
    "                 gpoints=None,\n",
    "                 rpoints=None,\n",
    "                 dtype=np.uint8\n",
    "                ):\n",
    "        \n",
    "        bgrfuncfilter.__init__(self,\n",
    "                              ut.createcurvefunc(vpoints),\n",
    "                              ut.createcurvefunc(vpoints),\n",
    "                              ut.createcurvefunc(vpoints),\n",
    "                              ut.createcurvefunc(vpoints),\n",
    "                               dtype\n",
    "                              )\n",
    "            \n",
    "            \n",
    "            \n",
    "class bgrPortraCurveFilter(bgrCurveFilter):   \n",
    "    \"\"\"A filter that applies Portra-like curves to bgr.\"\"\"        \n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):        \n",
    "        \n",
    "        bgrCurveFilter.__init__(            self,           \n",
    "                                vPoints = [(0,0),(23,20),(157,173),(255,255)],\n",
    "                                bPoints = [(0,0),(41,46),(231,228),(255,255)],\n",
    "                                gPoints = [(0,0),(52,47),(189,196),(255,255)],\n",
    "                                rPoints = [(0,0),(69,69),(213,218),(255,255)],\n",
    "                                dtype = dtype) \n",
    "        \n",
    "        \n",
    "        \n",
    "class bgrProviaCurveFilter(bgrCurveFilter):    \n",
    "    \"\"\"A filter that applies Provia-like curves to bgr.\"\"\"\n",
    "    def __init__(self, dtype = numpy.uint8):        \n",
    "        \n",
    "        bgrCurveFilter.__init__(self,            \n",
    "                                bPoints = [(0,0),(35,25),(205,227),(255,255)],\n",
    "                                gPoints = [(0,0),(27,21),(196,207),(255,255)],\n",
    "                                rPoints = [(0,0),(59,54),(202,210),(255,255)],\n",
    "                                dtype = dtype)\n",
    "        \n",
    "        \n",
    "        \n",
    "class bgrVelviaCurveFilter(bgrCurveFilter):\n",
    "    \"\"\"A filter that applies Velvia-like curves to bgr.\"\"\"\n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):        \n",
    "        \n",
    "        bgrCurveFilter.__init__(            self,\n",
    "                                vPoints = [(0,0),(128,118),(221,215),(255,255)],\n",
    "                                bPoints = [(0,0),(25,21),(122,153),(165,206),(255,255)],\n",
    "                                gPoints = [(0,0),(25,21),(95,102),(181,208),(255,255)],\n",
    "                                rPoints = [(0,0),(41,28),(183,209),(255,255)],\n",
    "                                dtype = dtype)        \n",
    "        \n",
    "        \n",
    "class bgrCrossProcessCurveFilter(bgrCurveFilter):\n",
    "    \"\"\"A filter that applies cross-process-like curves to bgr.\"\"\"\n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):        \n",
    "        \n",
    "        bgrCurveFilter.__init__(            self,\n",
    "                                bPoints = [(0,20),(255,235)],\n",
    "                                gPoints = [(0,0),(56,39),(208,226),(255,255)],\n",
    "                                rPoints = [(0,0),(56,22),(211,255),(255,255)],\n",
    "                                dtype = dtype)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def strokeedges(src,dst,blurksize=7,edgeksize=5):\n",
    "    \n",
    "    if blurksize>=3:\n",
    "        \n",
    "        blursrc=cv2.medianBlur(src,blurksize)\n",
    "        graysrc=cv2.cvtColor(blursrc,cv2.COLOR_bgr2GRAT)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        graysrc=cv2.cvtColor(src,cv2.COLOR_bgr2GRAY)\n",
    "        \n",
    "    cv2.laplacian(graysrc,cv2.cv.CV_8U,graysrc,ksize=edgeksize)\n",
    "    \n",
    "    normalizedinversealpha=(1.0/255)*(255-graysrc)\n",
    "    channels=cv2.split(src)\n",
    "    for channel in channels:\n",
    "        \n",
    "        channel[:]=channel*normalizedinversealpha\n",
    "        \n",
    "    cv2.merge(channels,dst)\n",
    "\n",
    "    \n",
    "    \n",
    "class vconvolutionfilter(object):\n",
    "    \"\"\"a filter that applies a convolution to v(or all of bgr)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,kernel):\n",
    "        \n",
    "        self._kernel=kernel\n",
    "        \n",
    "    def apply(self,src,dst):\n",
    "        \n",
    "        \"\"\"apply the filter with a bgr or gray source/destination\"\"\"\n",
    "        \n",
    "        cv2.filter2D(src,-1,self.kernel,dst)\n",
    "        \n",
    "        \n",
    "class sharpenfilter(vconvolutionfilter):\n",
    "    \"\"\"a sharpen filter with a 1-pixel radius\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        kernel=np.array([[-1, -1, -1],\n",
    "                         [-1,  9, -1],\n",
    "                         [-1, -1, -1]])\n",
    "        vconvolutionfilter.__init__(self,kernel)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "class findedgefilter(vconvolutionfilter):\n",
    "    \n",
    "    \"\"\"\n",
    "    an edge finding filter with a pixel radius\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        kernel=np.array([[-1 , -1,  -1],\n",
    "                          [-1  ,8   -1],\n",
    "                          [-1 ,-1,  -1]])\n",
    "        \n",
    "        vconvolutionfilter.__init__(self.kernel)\n",
    "        \n",
    "        \n",
    "        \n",
    "class blurfilter(vconvolutionfilter):\n",
    "    \n",
    "    \"\"\"a blur filter with a 2 pixel radius\"\"\"\n",
    "        \n",
    "    def __init__(self):\n",
    "            kernel= np.array([[0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                                 [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                                 [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                                 [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                                 [0.04, 0.04, 0.04, 0.04, 0.04]])\n",
    "            \n",
    "            vconvolutionfilter.__init__(self,kernel)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "class embossfilter(vconvolutionfilter):\n",
    "    \n",
    "    \"\"\"an emboss filter with a 1 pixel radius\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        kernel=np.array([[-2, -1, 0],\n",
    "                         [-1,  1, 1],\n",
    "                         [ 0,  1, 2]]) \n",
    "        \n",
    "        \n",
    "        vconvolutionfilter.__init__(self,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# util.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createcurvefunc(points):\n",
    "    \"\"\"return a function dervied from control points\"\"\"\n",
    "    \n",
    "    if points is None:\n",
    "        return None\n",
    "    numpoints=len(points)\n",
    "    \n",
    "    if numpoints <2:\n",
    "        return None\n",
    "    \n",
    "    xs,ys=zip(*points)\n",
    "    if numpoints<3:\n",
    "        kind=\"linear\"\n",
    "        \n",
    "    else:\n",
    "        kind=\"cubic\"\n",
    "        \n",
    "    return scipy.interpolate.interp1d(xs,ys,kind,bounds_error=False)\n",
    "\n",
    "\n",
    "def createlookuparray(func,length=256):\n",
    "    \n",
    "    \"\"\"return a lookup for whole-number input to a function\n",
    "    the look up array value are clamped to [0,length-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    if func is None:\n",
    "        return None\n",
    "    \n",
    "    lookuparray=np.empty(length)\n",
    "    \n",
    "    i=0\n",
    "    while i<length:\n",
    "        func_i=func(i)\n",
    "        lookuparray[i]=min(max(0,func_i),length-1)\n",
    "        i+=1\n",
    "    return lookuparray\n",
    "\n",
    "\n",
    "def applylookuparray(lookuparray,src,dst):\n",
    "    \"\"\"map a source to a destination using a lookup\"\"\"\n",
    "    \n",
    "    if lookuparray is None:\n",
    "        return \n",
    "    dst[:]=lookuparray[src]\n",
    "    \n",
    "    \n",
    "def createcompositionfunc(func0,func1):\n",
    "    \"\"\"return a composition of two function\"\"\"\n",
    "    \n",
    "    if func0 is None:\n",
    "        return func1\n",
    "    if func1 is None:\n",
    "        return func0\n",
    "    return lambda x:func0(func1(x))\n",
    "\n",
    "\n",
    "def createflatview(array):\n",
    "    \"\"\"return a 1d view of any array of any dimensionality\"\"\"\n",
    "    \n",
    "    flatview=array.view()\n",
    "    flatview.shape=array.size\n",
    "    return flatview\n",
    "\n",
    "def isgray(image):\n",
    "    \"\"\"return true if image is color \"\"\"\n",
    "    return image.ndim<3\n",
    "\n",
    "def widthheigthdividedby(image,divisor):\n",
    "    \"\"\"return an image dimension,divided by a value.\"\"\"\n",
    "    \n",
    "    h,w=image.shape[:2]\n",
    "    return (w/divisor,h/divisor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rects.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def outlinerect(image,rect,color):\n",
    "    if rect in None:\n",
    "        return\n",
    "    x,y,w,h=rect\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),color)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def copyrect(src,dst,srcrect,dstrect,\n",
    "             interpolation=cv2.INTER_LINEAR):\n",
    "    \"\"\"COPY part of the source part of the destination.\"\"\"\n",
    "    \n",
    "    x0,y0,w0,h0=srcrect\n",
    "    x1,y1,w1,h1=dstrect\n",
    "    \n",
    "    #resize the contents of the source sub-rectangle.\n",
    "    #put the results in destination sub-rectangle.\n",
    "    \n",
    "    dst[y1:y1+h1,x1:x1+w1]=cv2.resize(src[y0:y0+h0,x0:x0+w0],(w1,h1),interpolation=interpolation)\n",
    "    \n",
    "def swaprect(src,dst,rects,interpolation=cv2.INTER_LINEAR):\n",
    "    \n",
    "    \"\"\"COPY THE SOURCE WITH TWO OR MORE SUB RECTANGLE SWAPPED\"\"\"\n",
    "    \n",
    "    if dist is not src:\n",
    "        dst[:]=src\n",
    "    \n",
    "    numrects=len(rects)\n",
    "    \n",
    "    if numrects<2:\n",
    "        #copy the contents of last rectangle into temporay storage\n",
    "        \n",
    "        x,y,w,h=rects[numrects-1]\n",
    "        temp=src[y:y+h,x:x+w].copy()\n",
    "        \n",
    "        #copy the content of each rectangle into the next\n",
    "        \n",
    "        i=numrects-2\n",
    "        \n",
    "        while i>=0:\n",
    "            copyrect(src,dst,rects[i+1],interpolation)\n",
    "            i-=1\n",
    "            \n",
    "        #copy the temporarily stored content into the first rectangle\n",
    "        \n",
    "        copyrect(temp,\n",
    "                 dst,\n",
    "                 (0,0,w,h),\n",
    "                 rect[0],\n",
    "                interpolation)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tracker.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import rects\n",
    "import util\n",
    "\n",
    "\n",
    "class face(object):\n",
    "    \"\"\"\n",
    "    data on facial features\"\"\"\n",
    "    def __init__(self):\n",
    "        self.facerect=None\n",
    "        self.rigtheyerect=None\n",
    "        self.lefteyerect=None\n",
    "        self.noserect=None\n",
    "        self.mouthrect=None\n",
    "        \n",
    "class facetracker(object):\n",
    "    \"\"\"a tracker for facial features:face,eyes,nose,mouth\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 scaleFactor=1.2,\n",
    "                 minNeighbors=2,\n",
    "                flags=cv2.cv.CV_HAAR_SCALE_IMAGE):\n",
    "        \n",
    "        \n",
    "        self.scalefactor=scaleFactor\n",
    "        self.minneighbors=minNeighbors\n",
    "        self.flags=flags\n",
    "        \n",
    "        self._faces=[]\n",
    "        \n",
    "        self._faceclassifier=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "        self._eyeclassifier=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "        self._noseclassifier=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "        self._mouthclassifier=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def faces(self):\n",
    "        \"\"\"the tracked facial features\"\"\"\n",
    "        return self._faces\n",
    "    \n",
    "    \n",
    "    def update(self,image):\n",
    "        \"\"\"update the tracked facial features\"\"\"\n",
    "        \n",
    "        self._faces=[]\n",
    "        \n",
    "        if util.isgray(image):\n",
    "            image=cv2.equalizeHist(image)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            image=cv2.cvtColor(image,cv2.cv.CV_BGR2GRAY)\n",
    "            cv2.equalizeHist(image,image)\n",
    "            \n",
    "        minsize=util.widthheightdividedby(image,8)\n",
    "        \n",
    "        facerects=self._faceclassifier.detectMultiScale(image,\n",
    "                                                        self.scalefactor,\n",
    "                                                        self.minneighbors,\n",
    "                                                        self.flags,\n",
    "                                                        minsize)\n",
    "        \n",
    "        if facerects is not None:\n",
    "            \n",
    "            for facerect in facerects:\n",
    "                face=face()\n",
    "                \n",
    "                face.facerect=facerect\n",
    "                \n",
    "                \n",
    "                x,y,w,h=facerect\n",
    "                \n",
    "                # Seek an eye in the upper-left part of the face.                \n",
    "                searchRect = (x+w/7, y, w*2/7, h/2)                \n",
    "                face.leftEyeRect = self._detectOneObject(                    \n",
    "                    self._eyeClassifier, image, searchRect, 64)                                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Seek an eye in the upper-right part of the face.                \n",
    "                searchRect = (x+w*4/7, y, w*2/7, h/2)                \n",
    "                face.rightEyeRect = self._detectOneObject(                    \n",
    "                    self._eyeClassifier, image, searchRect, 64)                                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Seek a nose in the middle part of the face.                \n",
    "                searchRect = (x+w/4, y+h/4, w/2, h/2)                \n",
    "                face.noseRect = self._detectOneObject(                    \n",
    "                    self._noseClassifier, image, searchRect, 32)                                \n",
    "               \n",
    "                # Seek a mouth in the lower-middle part of the face.                \n",
    "                searchRect = (x+w/6, y+h*2/3, w*2/3, h/3)                \n",
    "                face.mouthRect = self._detectOneObject(                    \n",
    "                    self._mouthClassifier, image, searchRect, 16)                                \n",
    "                \n",
    "                \n",
    "                \n",
    "                self._faces.append(face)\n",
    "\n",
    "        \n",
    "        \n",
    "        def _detectoneobject(self,\n",
    "                             classifier,\n",
    "                             image,\n",
    "                             rect,\n",
    "                             imagesizetominsizeratio):\n",
    "            \n",
    "            x ,y ,w ,h=rect\n",
    "            \n",
    "            minsize=util.widthheightdividedby(image,\n",
    "                                               imagesizetominsizeratio)\n",
    "            \n",
    "            subimage=image[y:y+h,x:x+w]\n",
    "            \n",
    "            subrect=classifier.dectectMultiScale(subimage,\n",
    "                                                self.scalefactor,\n",
    "                                                self.minneighbors,\n",
    "                                                self.flags,\n",
    "                                                minsize)\n",
    "            \n",
    "            if len(subrect)==0:\n",
    "                return None\n",
    "            \n",
    "            subx,suby,subw,subh=subrects[0]\n",
    "            \n",
    "            return (x+subx,y+suby,w+subw,h+subh)\n",
    "        \n",
    "        \n",
    "        \n",
    "        def drawdebugrects(self,image):\n",
    "            \n",
    "            \"\"\"draw rectangle around the tracked facial features.\"\"\"\n",
    "            \n",
    "            if util.isgray(image):\n",
    "                faceColor = 255            \n",
    "                leftEyeColor = 255            \n",
    "                rightEyeColor = 255            \n",
    "                noseColor = 255           \n",
    "                mouthColor = 25\n",
    "                \n",
    "            else:\n",
    "                faceColor = (255, 255, 255) # white            \n",
    "                leftEyeColor = (0, 0, 255) # red           \n",
    "                rightEyeColor = (0, 255, 255) # yellow            \n",
    "                noseColor = (0, 255, 0) # green            \n",
    "                mouthColor = (255, 0, 0) # blue     \n",
    "                \n",
    "                \n",
    "            for face in self.faces:\n",
    "                \n",
    "                rects.outlinerect(image,face.facerect,facecolor)\n",
    "                rects.outlineRect(image, face.leftEyeRect, leftEyeColor)            \n",
    "                rects.outlineRect(image, face.rightEyeRect,rightEyeColor)            \n",
    "                rects.outlineRect(image, face.noseRect, noseColor)            \n",
    "                rects.outlineRect(image, face.mouthRect, mouthColor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
